vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \
  --port 8080 \
  --tensor-parallel-size 2 \
  --gpu-memory-utilization 0.85 \
  --enforce-eager \
  --dtype bfloat16 \
  --max-num-batched-tokens 8192 \
  --enable-chunked-prefill \
  --swap-space 16 \
  --max-num-seqs 1 \
  --rope_scaling '{"rope_type":"yarn","factor":4.0,"original_max_position_embeddings":32768}'